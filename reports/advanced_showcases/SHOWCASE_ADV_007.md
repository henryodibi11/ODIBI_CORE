# üöÄ Advanced Showcase #007
## IoT Windowed Kpi Pipeline

**Domain:** IoT  
**Batch Type:** Domain  
**Archetype:** Windowed Kpi  
**DAG Topology:** Linear  
**Complexity Level:** High  
**Timestamp:** 2025-11-02T22:12:19.190243  
**Status:** ‚úÖ SUCCESS

---

## üìñ Business Context

### Problem Statement
Anomaly detection needs low-latency processing

### Backstory
In the IoT domain, anomaly detection needs low-latency processing. The current system ingests data from AVRO, JSON sources, but lacks proper devices, events, telemetry reconciliation. This showcase demonstrates how ODIBI_CORE handles windowed kpi patterns to improve device_uptime and firmware_adoption visibility.

### Data Goal
Build a windowed kpi pipeline that consolidates 2-format sources, calculates device_uptime, firmware_adoption, and refreshes every 7d with full data quality validation.

### KPIs Tracked
device_uptime, firmware_adoption

### Data Formats
AVRO, JSON

---

## üèóÔ∏è Pipeline Architecture

**Archetype:** Windowed Kpi  
**DAG Topology:** Linear  
**Steps Executed:** 7

**Design Rationale:**  
1-min tumbling windows aggregate telemetry streams

**Trade-offs:**  
Watermark = 2min handles most late arrivals

---

## üß† What ODIBI_CORE Learned

**Business Context**: In IoT, 1-min tumbling windows aggregate telemetry streams. This showcase validated the windowed kpi pattern for handling devices, events data.

**Pipeline Execution**: ODIBI_CORE successfully orchestrated 7 steps across Linear topology in 0ms. The orchestrator fired 4 lifecycle events, providing real-time observability throughout the execution.

**Data Lineage**: Tracker captured 8 schema snapshots, preserving complete before/after states for audit trail. This demonstrates ODIBI_CORE's truth-preserving lineage - you can see exactly what happened to your data at each transformation step.

**Data Quality**: 1 validation checks ensured data integrity before publishing to the gold layer. Quality gates caught potential issues early, preventing bad data from reaching analytics consumers.

**Design Trade-offs**: Watermark = 2min handles most late arrivals. These choices balanced device_uptime requirements with operational constraints.

**Framework Insight**: This domain-batch showcase exercised 7 ODIBI_CORE components (ConfigLoader, Orchestrator, Tracker, EventEmitter, DAGBuilder, DAGExecutor), demonstrating seamless integration across the native stack. No external dependencies - pure Python orchestration.

---

## üìä Execution Metrics

| Metric | Value |
|--------|-------|
| **Steps Executed** | 7 |
| **Execution Time** | 25.00ms |
| **Events Fired** | 4 |
| **Tracker Snapshots** | 8 |
| **Cache Hits** | 0 |
| **Validation Checks** | 1 |
| **Components Used** | 7 |

---

## üîß Framework Components

- **ConfigLoader**
- **PandasEngineContext**
- **EventEmitter**
- **Orchestrator**
- **DAGExecutor**
- **DAGBuilder**
- **Tracker**

---

## üéØ Lifecycle Events

- `step_start`
- `pipeline_complete`
- `pipeline_start`
- `step_complete`

---

## üìù Status Report

**Final Status:** SUCCESS

**Result:** All components executed successfully. Pipeline demonstrates production-grade orchestration.

---

*Generated by ODIBI_CORE Advanced Showcase Executor*  
*Framework Version: 1.0 | Execution Mode: Advanced (100-Showcase Scale)*
